{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"swarmClassify_YOLO.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNHenCNQX6uYHP+HdYWd2ih"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"c-_zW8JQzK-L"},"source":["# Google Drive\n","The following code mounts your Google drive for use with Google CoLab. If you are not using CoLab, the following code will not work."]},{"cell_type":"code","metadata":{"id":"OIomnG8FznyW"},"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    COLAB = True\n","    print(\"Note: using Google CoLab\")\n","    %tensorflow_version 2.x\n","except:\n","    print(\"Note: not using Google CoLab\")\n","    COLAB = False\n","    \n","%cd drive/My Drive/phylum/bacteria/Compositional-Agents/classification/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MAhbxdOHz0Ch"},"source":["#import\n","The following packages will be used to implement our dataset preparation script"]},{"cell_type":"code","metadata":{"id":"flm5YtNTkChV"},"source":["import os\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DKfcRX7c0CKI"},"source":["# configuration"]},{"cell_type":"code","metadata":{"id":"2RQprML1s-nX"},"source":["def prepare_dataset(images_dir, weights_folder):\n","    # create a file for the labelled data (labelled_data.data)\n","    with open(images_dir + '/' + 'labelled_data.data', 'w') as data:\n","        # By using '\\n' we move to the next line\n","        data.write('classes = ' + str(c) + '\\n')\n","\n","        # Location of the train.txt file\n","        data.write('train = ' + images_dir + '/' + 'train.txt' + '\\n')\n","\n","        # Location of the test.txt file\n","        data.write('test = ' + images_dir + '/' + 'test.txt' + '\\n')\n","\n","        # Location of the classes.names file\n","        data.write('names = ' + images_dir + '/' + 'classes.names' + '\\n')\n","\n","        # Location where to save weights\n","        data.write('backup = ' + weights_folder)\n","\n","\n","    f_val = open(\"test.txt\", 'w')\n","    f_train = open(\"train.txt\", 'w')\n","\n","    path, dirs, files = next(os.walk(images_dir))\n","    data_size = len(files)\n","\n","    ind = 0\n","    data_test_size = int(0.2 * data_size)  # 20% of files used for testing\n","    test_array = random.sample(range(data_size), k=data_test_size)\n","\n","    for f in os.listdir(images_dir):\n","        if(f.split(\".\")[1] == \"JPG\" or \"jpg\"):\n","            ind += 1\n","\n","            if ind in test_array:\n","                f_val.write(images_dir+'/'+f+'\\n')\n","            else:\n","                f_train.write(images_dir+'/'+f+'\\n')\n","\n","    print(\"Dataset prepared. Now ready to train YOLO with your custom images and classes\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B9LZo0FDtnHC"},"source":["# location of dataset\n","DATA_PATH = \"data/swarming\"\n","\n","# run params\n","SECTION = 'yolo'\n","RUN_ID = '0000'\n","DATA_NAME = 'swarming_yolo'\n","MODEL_FOLDER = 'models/{}/'.format(SECTION)\n","MODEL_FOLDER += '_'.join([RUN_ID, DATA_NAME])  # where to save the models\n","print(MODEL_FOLDER)\n","\n","if not os.path.exists(MODEL_FOLDER):\n","    os.makedirs(MODEL_FOLDER)\n","    os.mkdir(os.path.join(MODEL_FOLDER, 'weights'))\n","\n","images_dir = './data/' + DATA_NAME"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrbaZJsDuB0Y"},"source":["# create a file classes.names from the classes.txt that the YOLO format uses\n","# counter for classes\n","c = 0\n","\n","with open(images_dir + '/' + 'classes.names', 'w') as names, \\\n","     open(images_dir + '/' + 'classes.txt', 'r') as txt:\n","\n","    # go through all lines in txt file and writing them into names file\n","    for line in txt:\n","        names.write(line)\n","        # increment counter\n","        c += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c8v4GGwruDBg"},"source":["# create files labelled_data.data and train.txt and test.txt for train/test split\n","prepare_dataset(images_dir, MODEL_FOLDER + '/weights/')"],"execution_count":null,"outputs":[]}]}